{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground State and Excited State of H2 Molecule using VQE and VQD\n",
    "## Introduction\n",
    "\n",
    "Quantum computing holds the promise of revolutionizing many fields, and one of the most exciting applications is in computational chemistry. Traditional methods for simulating molecular systems become computationally intractable as the size of the system increases. Quantum computers offer a potential solution to this problem by exploiting the quantum properties of matter to efficiently simulate molecular behavior.\n",
    "\n",
    "In this notebook, we will employ two quantum algorithms, the Variational Quantum Eigensolver (VQE) and the Variational Quantum Deflation (VQD), to find the ground state and excited state of the $H_2$ molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import functools \n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import optax\n",
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "\n",
    "h2_dataset = qml.data.load(\"qchem\", molname=\"H2\", bondlength=0.742, basis=\"STO-3G\")\n",
    "h2 = h2_dataset[0]\n",
    "H, qubits = h2.hamiltonian, len(h2.hamiltonian.wires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 0], dtype=int64, requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2.hf_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VQE\n",
    "The VQE needs the following:\n",
    "- An Ansatz\n",
    "- Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of qubits =  4\n",
      "The Hamiltonian is    (-0.22250914236600539) [Z2]\n",
      "+ (-0.22250914236600539) [Z3]\n",
      "+ (-0.09963387941370971) [I0]\n",
      "+ (0.17110545123720225) [Z1]\n",
      "+ (0.17110545123720233) [Z0]\n",
      "+ (0.12051027989546245) [Z0 Z2]\n",
      "+ (0.12051027989546245) [Z1 Z3]\n",
      "+ (0.16584090244119712) [Z0 Z3]\n",
      "+ (0.16584090244119712) [Z1 Z2]\n",
      "+ (0.16859349595532533) [Z0 Z1]\n",
      "+ (0.1743207725924201) [Z2 Z3]\n",
      "+ (-0.04533062254573469) [Y0 Y1 X2 X3]\n",
      "+ (-0.04533062254573469) [X0 X1 Y2 Y3]\n",
      "+ (0.04533062254573469) [Y0 X1 X2 Y3]\n",
      "+ (0.04533062254573469) [X0 Y1 Y2 X3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of qubits = \", qubits)\n",
    "print(\"The Hamiltonian is \", H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groudtruth\n",
    "Let's look at some of the eperical measured value\n",
    "- Ground state energy:\n",
    "  - $H$ atom: $E_1=-13.6eV$\n",
    "  - $H_2$ molecule: $-1.136*27.21 Ha=-30.91 eV$\n",
    "- 1st level excitation energy for $H$ atom: $E_2=\\frac{-13.6}{4}=-3.4eV$\n",
    "- The energy to transition from $E_1$ to $E_2$ for $H$ atom: $10.2eV$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hatree_energy_to_ev(hatree: float):\n",
    "    return hatree*27.2107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ev_energy_to_hatree(ev: float):\n",
    "    return ev/27.2107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin training\n",
    "Let's set some expectation for the optimization process. Thankfully, $H_2$ is well studied and we have all we need in the `dataset` library to know the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ansatz\n",
    "\n",
    "Before any run, we can assume that the Jordan Wigner representation `[1 1 0 0]` has the lowest energy. Let's calculate that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=qubits)\n",
    "@qml.qnode(dev)\n",
    "def circuit_expected():\n",
    "    qml.BasisState(h2.hf_state, wires = range(qubits))\n",
    "    for op in h2.vqe_gates:\n",
    "        qml.apply(op)\n",
    "    return qml.probs(), qml.state(), qml.expval(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Hamiltonian doesn't have a canonical representation, we have to create a work around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea herer is, for `Z(1)`, we convert into `I(0) @ Z(1) @ I(1) @ I(2)`, and do the same for every Hamiltonian operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF state: [1 1 0 0]\n",
      "Ground state energy H_2: -1.1363765762751892\n"
     ]
    }
   ],
   "source": [
    "print(f\"HF state: {h2.hf_state}\")\n",
    "prob, state, expval = circuit_expected()\n",
    "print(f\"Ground state energy H_2: {expval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.        +0.j,  0.        +0.j,  0.        +0.j,\n",
       "        -0.13619566+0.j,  0.        +0.j,  0.        +0.j,\n",
       "         0.        +0.j,  0.        +0.j,  0.        +0.j,\n",
       "         0.        +0.j,  0.        +0.j,  0.        +0.j,\n",
       "         0.99068196+0.j,  0.        +0.j,  0.        +0.j,\n",
       "         0.        +0.j], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit_reverse(state):\n",
    "    qml.AmplitudeEmbedding(state,wires=range(4))\n",
    "    return qml.state()\n",
    "    \n",
    "circuit_reverse(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-30.9216021, requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatree_energy_to_ev(expval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the superposition with themselves and the higher/lower energy level (excite/de-excite). Note that in `h2.vqe_gates` we already have the value for $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: â”€â•­|Î¨âŸ©â”€â•­GÂ²(0.27)â”€â”¤  Probs  State â•­<ð“—>\n",
      "1: â”€â”œ|Î¨âŸ©â”€â”œGÂ²(0.27)â”€â”¤  Probs  State â”œ<ð“—>\n",
      "2: â”€â”œ|Î¨âŸ©â”€â”œGÂ²(0.27)â”€â”¤  Probs  State â”œ<ð“—>\n",
      "3: â”€â•°|Î¨âŸ©â”€â•°GÂ²(0.27)â”€â”¤  Probs  State â•°<ð“—>\n"
     ]
    }
   ],
   "source": [
    "print(qml.draw(circuit_expected)())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would define the same circuit but without the $\\theta$. Given 2 $H$ and 4 qubits, after a double excitation, the HF is the superposition of the states\n",
    "$$\\alpha\\ket{1100}+\\beta\\ket{0011}:=\\cos(\\theta)\\ket{1100}-\\sin(\\theta)\\ket{0011}$$\n",
    "\n",
    "[comment]: # ($\\alpha\\ket{110000}+\\beta\\ket{001100}+\\gamma\\ket{000011}$ this is H3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@qml.qnode(dev, diff_method=\"backprop\")\n",
    "def circuit(param):\n",
    "    qml.BasisState(h2.hf_state, wires=range(qubits))\n",
    "    qml.DoubleExcitation(param, wires=[0, 1, 2, 3])\n",
    "    return qml.state(), qml.expval(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the lost function\n",
    "Remember that the lost function is the second ingredient. We use the first two equations in [this paper](https://www.nature.com/articles/s41524-023-00965-1)\n",
    "\\begin{align}\n",
    "C_0\\left( {{{\\mathbf{\\theta }}}} \\right) &= \\left\\langle {{\\Psi}\\left( {{{\\mathbf{\\theta }}}} \\right)\\left| {\\hat H} \\right|{\\Psi}\\left( {{{\\mathbf{\\theta }}}} \\right)} \\right\\rangle \\label{eq:loss_1} \\tag{1} \\\\\n",
    "C_1\\left( {{{\\mathbf{\\theta }}}} \\right) &= \\left\\langle {{\\Psi}\\left( {{{\\mathbf{\\theta }}}} \\right)\\left| {\\hat H} \\right|{\\Psi}\\left( {{{\\mathbf{\\theta }}}} \\right)} \\right\\rangle + \\beta \\left| {\\left\\langle {{\\Psi}\\left( {{{\\mathbf{\\theta }}}} \\right)\\left| {{\\Psi}_0} \\right.} \\right\\rangle } \\right|^2 \\label{eq:loss_2} \\tag{2}\n",
    "\\end{align}\n",
    "\n",
    "We can then define a lost function\n",
    "\n",
    "At first sight, it might raises some eyebrow for someone who is from a ML background, because we define the loss function based on the predicted and the groundtruth. However we do not have any groundtruth value here. In this context, a loss function is just a function that we want to minimize.\n",
    "\n",
    "Now we proceed to optimize the variational parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in equation \\eqref{eq:loss_2}, we have the term $\\beta \\left| {\\left\\langle {{\\Psi}\\left( {{{\\mathbf{\\theta }}}} \\right)\\left| {{\\Psi}_0} \\right.} \\right\\rangle } \\right|^2$, which is not easy to compute directly in a quantum machine. To make everything pure quantum, we rely on a swap test as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_swap = qml.device(\"default.qubit\", wires=1+2*qubits)\n",
    "\n",
    "@qml.qnode(dev_swap)\n",
    "def dot_product_circuit(psi, phi):\n",
    "    \"\"\"\n",
    "    If psi and phi are orthogonal (|âŸ¨psi|phiâŸ©|^2 = 1) then the probability that 0 is measured is 1/2 \n",
    "    If the states are equal (|âŸ¨psi|phiâŸ©|^2 = 1), then the probability that 0 is measured is 1.\n",
    "    The measurement on the 0th wire, or 1st qubit is 0.5+0.5(|âŸ¨psi|phiâŸ©|^2)\n",
    "    \"\"\"\n",
    "      \n",
    "    qml.AmplitudeEmbedding(features=psi, wires=range(1,qubits+1))\n",
    "    qml.AmplitudeEmbedding(features=phi, wires=range(qubits+1,1+2*qubits))\n",
    "    qml.Hadamard(0)\n",
    "    for i in range(1, qubits+1):\n",
    "        qml.CSWAP([0,i,i+qubits])\n",
    "    qml.Hadamard(0)\n",
    "    return qml.probs(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_1_left, case_1_right = np.zeros(16), np.zeros(16)\n",
    "case_1_left[12] = 1\n",
    "case_1_right[12] = 1\n",
    "assert np.all(np.isclose(dot_product_circuit(case_1_left,case_1_right), [1,0]))\n",
    "\n",
    "case_2_left, case_2_right = np.zeros(16), np.zeros(16)\n",
    "case_2_left[12] = 1/np.sqrt(2)\n",
    "case_2_left[13] = 1/np.sqrt(2)\n",
    "case_2_right[14] = 1/np.sqrt(2)\n",
    "case_2_right[15] = 1/np.sqrt(2)\n",
    "assert np.all(np.isclose(dot_product_circuit(case_2_left, case_2_right), [0.5,0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.real makes sense?\n",
    "def loss_fn_1(theta):\n",
    "    \"\"\"\n",
    "    Pure expectation value\n",
    "    \"\"\"\n",
    "    _, expval = circuit(theta)\n",
    "    return expval\n",
    "\n",
    "def loss_fn_2(theta, theta_0, beta):\n",
    "    \"\"\"\n",
    "    Expectation value\n",
    "    Depends on the molecule, beta must be large enough to jump over the gap\n",
    "    \"\"\"\n",
    "    state, expval = circuit(theta)\n",
    "    state_0, _ = circuit(theta_0)\n",
    "    dot_prod = (dot_product_circuit(state, state_0)[0] - 0.5)/0.5    \n",
    "    return expval + beta*dot_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(loss_f, **kwargs):\n",
    "    theta = np.array(0.)\n",
    "\n",
    "    # store the values of the cost function\n",
    "    energy = [loss_fn_1(theta)]\n",
    "    conv_tol = 1e-6\n",
    "    max_iterations = 100\n",
    "    opt = optax.sgd(learning_rate=0.4)\n",
    "    \n",
    "    # store the values of the circuit parameter\n",
    "    angle = [theta]\n",
    "    \n",
    "    opt_state = opt.init(theta)\n",
    "    \n",
    "    for n in range(max_iterations):\n",
    "        gradient = jax.grad(loss_f)(theta, **kwargs)\n",
    "        updates, opt_state = opt.update(gradient, opt_state)\n",
    "        theta = optax.apply_updates(theta, updates)\n",
    "        \n",
    "        angle.append(theta)\n",
    "        energy.append(loss_fn_1(theta))\n",
    "    \n",
    "        conv = np.abs(energy[-1] - energy[-2])\n",
    "    \n",
    "        if n % 5 == 0:\n",
    "            print(f\"Step = {n},  Energy = {energy[-1]:.8f} Ha\")\n",
    "    \n",
    "        if conv <= conv_tol:\n",
    "            break\n",
    "    return angle[-1], energy[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the ground state optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\code\\vqeac\\.venv\\lib\\site-packages\\pennylane\\math\\utils.py:227: UserWarning: Contains tensors of types {'jax', 'autograd'}; dispatch will prioritize TensorFlow, PyTorch, and  Jax over Autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n",
      "C:\\code\\vqeac\\.venv\\lib\\site-packages\\jax\\_src\\lax\\lax.py:2740: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n",
      "C:\\code\\vqeac\\.venv\\lib\\site-packages\\pennylane\\math\\utils.py:227: UserWarning: Contains tensors of types {'jax', 'autograd'}; dispatch will prioritize TensorFlow, PyTorch, and  Jax over Autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step = 0,  Energy = -1.12772109 Ha\n",
      "Step = 5,  Energy = -1.13706903 Ha\n",
      "Step = 10,  Energy = -1.13725940 Ha\n"
     ]
    }
   ],
   "source": [
    "ground_state_theta, ground_state_energy = optimize(loss_fn_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the 1st excited state optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to choose the value for $\\beta$, it has to be big enough to facilitate a jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\code\\vqeac\\.venv\\lib\\site-packages\\pennylane\\math\\utils.py:227: UserWarning: Contains tensors of types {'jax', 'autograd'}; dispatch will prioritize TensorFlow, PyTorch, and  Jax over Autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step = 0,  Energy = -1.08055668 Ha\n",
      "Step = 5,  Energy = 0.42901254 Ha\n",
      "Step = 10,  Energy = 0.47841911 Ha\n"
     ]
    }
   ],
   "source": [
    "first_excite_theta, first_excite_energy = optimize(loss_fn_2, theta_0=ground_state_theta, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(-30.94570863, dtype=float64), Array(13.01809466, dtype=float64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatree_energy_to_ev(ground_state_energy), hatree_energy_to_ev(first_excite_energy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
